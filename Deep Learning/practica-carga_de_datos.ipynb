{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empiezo cargando los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14001, 89)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "was_loaded = np.load('was_loaded.npy')\n",
    "data = pd.read_csv('airbnb-listings.csv',sep=';', decimal='.')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpio los registros sin imágenes y me creo una variable para ir guardando los índices que voy a eliminar. Así los elimino todos de golpe y me aseguro que los índices que guardo en el csv al final van a servir para el array de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idx_to_drop = []\n",
    "total_idx_to_drop += data[was_loaded!=1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Listing Url', 'Scrape ID', 'Last Scraped', 'Name', 'Summary',\n",
       "       'Space', 'Description', 'Experiences Offered', 'Neighborhood Overview',\n",
       "       'Notes', 'Transit', 'Access', 'Interaction', 'House Rules',\n",
       "       'Thumbnail Url', 'Medium Url', 'Picture Url', 'XL Picture Url',\n",
       "       'Host ID', 'Host URL', 'Host Name', 'Host Since', 'Host Location',\n",
       "       'Host About', 'Host Response Time', 'Host Response Rate',\n",
       "       'Host Acceptance Rate', 'Host Thumbnail Url', 'Host Picture Url',\n",
       "       'Host Neighbourhood', 'Host Listings Count',\n",
       "       'Host Total Listings Count', 'Host Verifications', 'Street',\n",
       "       'Neighbourhood', 'Neighbourhood Cleansed',\n",
       "       'Neighbourhood Group Cleansed', 'City', 'State', 'Zipcode', 'Market',\n",
       "       'Smart Location', 'Country Code', 'Country', 'Latitude', 'Longitude',\n",
       "       'Property Type', 'Room Type', 'Accommodates', 'Bathrooms', 'Bedrooms',\n",
       "       'Beds', 'Bed Type', 'Amenities', 'Square Feet', 'Price', 'Weekly Price',\n",
       "       'Monthly Price', 'Security Deposit', 'Cleaning Fee', 'Guests Included',\n",
       "       'Extra People', 'Minimum Nights', 'Maximum Nights', 'Calendar Updated',\n",
       "       'Has Availability', 'Availability 30', 'Availability 60',\n",
       "       'Availability 90', 'Availability 365', 'Calendar last Scraped',\n",
       "       'Number of Reviews', 'First Review', 'Last Review',\n",
       "       'Review Scores Rating', 'Review Scores Accuracy',\n",
       "       'Review Scores Cleanliness', 'Review Scores Checkin',\n",
       "       'Review Scores Communication', 'Review Scores Location',\n",
       "       'Review Scores Value', 'License', 'Jurisdiction Names',\n",
       "       'Cancellation Policy', 'Calculated host listings count',\n",
       "       'Reviews per Month', 'Geolocation', 'Features'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo únicamente con descripciones y variables numéricas (elimino IDs y enlaces). También elimino las variables Monthly Price y Weekly Price porque forman parte de la variable objetivo (el precio) y con ellas estaría haciendo trampa. También me quito algunas variables que carecen de contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['ID','Listing Url','Scrape ID','Thumbnail Url','Medium Url','Picture Url','XL Picture Url',\n",
    "         'Host ID','Host URL','Host Thumbnail Url','Host Picture Url','Monthly Price','Weekly Price',\n",
    "         'Experiences Offered','Host Acceptance Rate','Jurisdiction Names','Has Availability','Geolocation']\n",
    "\n",
    "data = data.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También voy a filtrar para quedarme únicamente con los registros de Madrid, ya que solamente quiero trabajar con los datos de Madrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idx_to_drop += data[(data.City != 'Madrid') & (data.City != 'madrid')].index.tolist()\n",
    "\n",
    "# Ahora también puedo borrar esta columna y las que hacen referencia al país, que ya no me aportan nada.\n",
    "data = data.drop(columns=['City','State','Country Code','Country','Smart Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la variable objetivo es el precio, no tendría sentido entrenar con datos cuyo precio es desconocido, así que descartaré de mi dataset todos aquellos apartamentos cuyo precio sea nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_idx_to_drop += data[data[\"Price\"].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me creo una función para limpiar un poco por encima los datos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, categorical):\n",
    "    \n",
    "    columns_to_drop = []\n",
    "    idx_to_drop = []\n",
    "    \n",
    "    for col in categorical:\n",
    "        counts = data[col].value_counts().tolist()\n",
    "        if counts[0] > sum(counts)*0.95 or counts[0] < sum(counts)*0.10 or sum(data[col].isnull()) > sum(counts)/2:\n",
    "            print(f'Deleting column {col} with {len(counts)} distinct values and {sum(data[col].isnull())} nulls')\n",
    "            columns_to_drop.append(col)\n",
    "        else:\n",
    "            vals = data[col].value_counts().keys().tolist()\n",
    "            for val, count in zip(vals,counts):\n",
    "                if count < 25:\n",
    "                    idx_to_drop += [i for i in data[data[col]==val].index.tolist() if i not in idx_to_drop]\n",
    "    \n",
    "    return columns_to_drop, idx_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting column Last Scraped with 2 distinct values and 0 nulls\n",
      "Deleting column Host Since with 2065 distinct values and 3 nulls\n",
      "Deleting column Host Name with 3053 distinct values and 3 nulls\n",
      "Deleting column Host Neighbourhood with 130 distinct values and 3709 nulls\n",
      "Deleting column Neighbourhood with 96 distinct values and 5005 nulls\n",
      "Deleting column Market with 7 distinct values and 50 nulls\n",
      "Deleting column Bed Type with 5 distinct values and 0 nulls\n",
      "Deleting column License with 314 distinct values and 13668 nulls\n",
      "Deleting column First Review with 1629 distinct values and 3007 nulls\n",
      "Deleting column Last Review with 720 distinct values and 3008 nulls\n"
     ]
    }
   ],
   "source": [
    "categorical = ['Last Scraped','Host Since','Host Name','Host Response Time','Host Location',\n",
    "               'Calendar Updated','Calendar last Scraped','Host Neighbourhood','Neighbourhood',\n",
    "               'Neighbourhood Cleansed','Neighbourhood Group Cleansed','Zipcode','Market','Property Type',\n",
    "               'Room Type','Bed Type','License','Cancellation Policy','First Review','Last Review']\n",
    "\n",
    "dropcolumns, dropindex = clean_data(data, categorical)\n",
    "total_idx_to_drop += dropindex\n",
    "clean_data = data.drop(index=total_idx_to_drop, columns=dropcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me separo los datos en train, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(clean_data, test_size=0.2, shuffle=True)\n",
    "train, val = train_test_split(train, test_size=0.1, shuffle=True)\n",
    "\n",
    "# Me guardo los datos para asegurarme de no modificarlos accidentalmente.\n",
    "train.to_csv('./train.csv', sep=';', decimal='.', index=True)\n",
    "val.to_csv('./val.csv', sep=';', decimal='.', index=True)\n",
    "test.to_csv('./test.csv', sep=';', decimal='.', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
