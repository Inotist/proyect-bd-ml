{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda y construcción del modelo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./train.csv',sep=';', decimal='.')\n",
    "val = pd.read_csv('./val.csv',sep=';', decimal='.')\n",
    "test = pd.read_csv('./test.csv',sep=';', decimal='.')\n",
    "\n",
    "images = np.load('images.npy')\n",
    "train_imgs = images[train['Unnamed: 0']]\n",
    "val_imgs = images[val['Unnamed: 0']]\n",
    "test_imgs = images[test['Unnamed: 0']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraigo la variable objetivo y dropeo los índices para empezar a trabajar con los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train.Price\n",
    "Y_val = val.Price\n",
    "Y_test = test.Price\n",
    "\n",
    "X_train = train.drop(columns=['Unnamed: 0','Price'])\n",
    "X_val = val.drop(columns=['Unnamed: 0','Price'])\n",
    "X_test = test.drop(columns=['Unnamed: 0','Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo los paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.engine import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.applications import VGG16\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función me permite crear un modelo denso lineal o categórico en base al parámetro \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense(dim, linear=False):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=dim, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    \n",
    "    if linear:\n",
    "        model.add(Dense(3, activation='relu'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "    else:\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echo un primer vistazo al modelo con los hiperparámetros que mejor suelen funcionar a nivel general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6634 samples, validate on 738 samples\n",
      "Epoch 1/50\n",
      "6634/6634 [==============================] - 1s 78us/step - loss: 6907.0864 - mean_squared_error: 6907.0859 - val_loss: 23200.1138 - val_mean_squared_error: 23200.1133\n",
      "Epoch 2/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 2493.6182 - mean_squared_error: 2493.6187 - val_loss: 2794.4601 - val_mean_squared_error: 2794.4600\n",
      "Epoch 3/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 2252.8969 - mean_squared_error: 2252.8970 - val_loss: 2604.1251 - val_mean_squared_error: 2604.1252\n",
      "Epoch 4/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 2028.0679 - mean_squared_error: 2028.0680 - val_loss: 2567.1138 - val_mean_squared_error: 2567.1138\n",
      "Epoch 5/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1822.1770 - mean_squared_error: 1822.1772 - val_loss: 2002.5008 - val_mean_squared_error: 2002.5007\n",
      "Epoch 6/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1718.2357 - mean_squared_error: 1718.2357 - val_loss: 2100.6427 - val_mean_squared_error: 2100.6431\n",
      "Epoch 7/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1662.7890 - mean_squared_error: 1662.7891 - val_loss: 2306.5342 - val_mean_squared_error: 2306.5344\n",
      "Epoch 8/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1580.4290 - mean_squared_error: 1580.4290 - val_loss: 2698.7660 - val_mean_squared_error: 2698.7664\n",
      "Epoch 9/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1522.3847 - mean_squared_error: 1522.3851 - val_loss: 2115.0977 - val_mean_squared_error: 2115.0977\n",
      "Epoch 10/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1469.8688 - mean_squared_error: 1469.8689 - val_loss: 1757.1051 - val_mean_squared_error: 1757.1050\n",
      "Epoch 11/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1424.8642 - mean_squared_error: 1424.8644 - val_loss: 2171.8210 - val_mean_squared_error: 2171.8210\n",
      "Epoch 12/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1436.3297 - mean_squared_error: 1436.3297 - val_loss: 1827.8482 - val_mean_squared_error: 1827.8480\n",
      "Epoch 13/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1413.3674 - mean_squared_error: 1413.3672 - val_loss: 1978.7959 - val_mean_squared_error: 1978.7960\n",
      "Epoch 14/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1367.5741 - mean_squared_error: 1367.5742 - val_loss: 1682.2053 - val_mean_squared_error: 1682.2053\n",
      "Epoch 15/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1328.6401 - mean_squared_error: 1328.6400 - val_loss: 3297.3931 - val_mean_squared_error: 3297.3931\n",
      "Epoch 16/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1424.9060 - mean_squared_error: 1424.9059 - val_loss: 2544.6916 - val_mean_squared_error: 2544.6917\n",
      "Epoch 17/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1480.2897 - mean_squared_error: 1480.2903 - val_loss: 1664.2440 - val_mean_squared_error: 1664.2440\n",
      "Epoch 18/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1287.8791 - mean_squared_error: 1287.8788 - val_loss: 1726.3583 - val_mean_squared_error: 1726.3584\n",
      "Epoch 19/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1283.6053 - mean_squared_error: 1283.6055 - val_loss: 1663.4077 - val_mean_squared_error: 1663.4077\n",
      "Epoch 20/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1288.9153 - mean_squared_error: 1288.9154 - val_loss: 1635.7458 - val_mean_squared_error: 1635.7457\n",
      "Epoch 21/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1270.8863 - mean_squared_error: 1270.8864 - val_loss: 1601.2451 - val_mean_squared_error: 1601.2449\n",
      "Epoch 22/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1275.7727 - mean_squared_error: 1275.7728 - val_loss: 1612.1572 - val_mean_squared_error: 1612.1572\n",
      "Epoch 23/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1254.2167 - mean_squared_error: 1254.2166 - val_loss: 1570.4490 - val_mean_squared_error: 1570.4490\n",
      "Epoch 24/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1282.2425 - mean_squared_error: 1282.2424 - val_loss: 1556.5707 - val_mean_squared_error: 1556.5707\n",
      "Epoch 25/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1226.5478 - mean_squared_error: 1226.5477 - val_loss: 1596.8353 - val_mean_squared_error: 1596.8353\n",
      "Epoch 26/50\n",
      "6634/6634 [==============================] - 0s 33us/step - loss: 1239.0731 - mean_squared_error: 1239.0731 - val_loss: 1592.2066 - val_mean_squared_error: 1592.2067\n",
      "Epoch 27/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1227.6435 - mean_squared_error: 1227.6436 - val_loss: 1716.2253 - val_mean_squared_error: 1716.2252\n",
      "Epoch 28/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1177.9006 - mean_squared_error: 1177.9006 - val_loss: 1559.5836 - val_mean_squared_error: 1559.5835\n",
      "Epoch 29/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1155.6774 - mean_squared_error: 1155.6776 - val_loss: 1570.1703 - val_mean_squared_error: 1570.1704\n",
      "Epoch 30/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1190.1747 - mean_squared_error: 1190.1746 - val_loss: 2831.3533 - val_mean_squared_error: 2831.3533\n",
      "Epoch 31/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1168.6918 - mean_squared_error: 1168.6921 - val_loss: 1668.5662 - val_mean_squared_error: 1668.5663\n",
      "Epoch 32/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1144.8882 - mean_squared_error: 1144.8881 - val_loss: 23958.0174 - val_mean_squared_error: 23958.0195\n",
      "Epoch 33/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1128.9470 - mean_squared_error: 1128.9469 - val_loss: 1564.9642 - val_mean_squared_error: 1564.9642\n",
      "Epoch 34/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1160.0168 - mean_squared_error: 1160.0168 - val_loss: 1571.8649 - val_mean_squared_error: 1571.8650\n",
      "Epoch 35/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1151.1633 - mean_squared_error: 1151.1635 - val_loss: 1639.5522 - val_mean_squared_error: 1639.5521\n",
      "Epoch 36/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1148.0777 - mean_squared_error: 1148.0778 - val_loss: 1633.7205 - val_mean_squared_error: 1633.7203\n",
      "Epoch 37/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1098.6894 - mean_squared_error: 1098.6892 - val_loss: 1549.3839 - val_mean_squared_error: 1549.3838\n",
      "Epoch 38/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1113.1105 - mean_squared_error: 1113.1104 - val_loss: 1550.4967 - val_mean_squared_error: 1550.4965\n",
      "Epoch 39/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1096.7757 - mean_squared_error: 1096.7755 - val_loss: 1686.4953 - val_mean_squared_error: 1686.4952\n",
      "Epoch 40/50\n",
      "6634/6634 [==============================] - 0s 30us/step - loss: 1111.9445 - mean_squared_error: 1111.9446 - val_loss: 1529.9074 - val_mean_squared_error: 1529.9075\n",
      "Epoch 41/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1170.3837 - mean_squared_error: 1170.3838 - val_loss: 1597.5627 - val_mean_squared_error: 1597.5629\n",
      "Epoch 42/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1077.2687 - mean_squared_error: 1077.2688 - val_loss: 1515.2194 - val_mean_squared_error: 1515.2194\n",
      "Epoch 43/50\n",
      "6634/6634 [==============================] - 0s 32us/step - loss: 1068.5291 - mean_squared_error: 1068.5291 - val_loss: 1657.6419 - val_mean_squared_error: 1657.6420\n",
      "Epoch 44/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1147.8977 - mean_squared_error: 1147.8982 - val_loss: 1647.7410 - val_mean_squared_error: 1647.7412\n",
      "Epoch 45/50\n",
      "6634/6634 [==============================] - 0s 33us/step - loss: 1058.0946 - mean_squared_error: 1058.0947 - val_loss: 1466.5411 - val_mean_squared_error: 1466.5414\n",
      "Epoch 46/50\n",
      "6634/6634 [==============================] - 0s 33us/step - loss: 1104.0663 - mean_squared_error: 1104.0662 - val_loss: 3145.9849 - val_mean_squared_error: 3145.9851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "6634/6634 [==============================] - 0s 34us/step - loss: 1052.6031 - mean_squared_error: 1052.6031 - val_loss: 1536.9322 - val_mean_squared_error: 1536.9321\n",
      "Epoch 48/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1014.3397 - mean_squared_error: 1014.3396 - val_loss: 1517.0386 - val_mean_squared_error: 1517.0386\n",
      "Epoch 49/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1052.9542 - mean_squared_error: 1052.9542 - val_loss: 1752.5487 - val_mean_squared_error: 1752.5488\n",
      "Epoch 50/50\n",
      "6634/6634 [==============================] - 0s 31us/step - loss: 1057.8302 - mean_squared_error: 1057.8302 - val_loss: 1579.1593 - val_mean_squared_error: 1579.1594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b779f8fc88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atts_model = create_dense(X_train.shape[1], linear=True)\n",
    "atts_model.compile(loss='mse', optimizer='adam' , metrics=[MeanSquaredError()])\n",
    "atts_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en test: 1196.0784859908872\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE en test: {np.mean(((atts_model.predict(X_test) - Y_test.to_numpy().reshape(-1,1))**2).mean(axis=1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es excesivamente malo para ser un modelo tan simple, el error medio es de unos 34€. Ahora voy a definir un modelo para trabajar con las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función construye un modelo sencillo que puede generar una salida lineal o categórica dependiendo del parámetro \"linear\", y también permite añadir una salida final partiendo de una arquiectura base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(shape, base=None, linear=False, density=128, mode='trainable'):\n",
    "    \n",
    "    if base:\n",
    "        \n",
    "        if mode == 'transfer_learning':\n",
    "            for layer in base.layers: \n",
    "                layer.trainable = False            \n",
    "        \n",
    "        model = base.layers[-1].output\n",
    "        model = Flatten()(model)\n",
    "        model = Dense(density, activation='relu')(model)\n",
    "        model = Dropout(0.3)(model)\n",
    "        \n",
    "        if linear:\n",
    "            model = Dense(1, activation='linear')(model)\n",
    "        else:\n",
    "            model = Dense(3, activation='softmax')(model)\n",
    "            \n",
    "        model = Model(base.input, model)\n",
    "    \n",
    "    else:\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=shape))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "        model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(density, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "        if linear:\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "        else:\n",
    "            model.add(Dense(3, activation='softmax'))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescalo las imágenes a la mitad de su resolución original por cuestiones de memoria RAM de mi GPU y después estandarizo los datos para que el modelo trabaje con números entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "\n",
    "for shape in (train_imgs.shape, val_imgs.shape, test_imgs.shape):\n",
    "    shapes.append((shape[0],shape[1]//2,shape[2]//2,shape[3]))\n",
    "    \n",
    "train_imgs_res = np.zeros(shapes[0], dtype=int)\n",
    "val_imgs_res = np.zeros(shapes[1], dtype=int)\n",
    "test_imgs_res = np.zeros(shapes[2], dtype=int)        \n",
    "\n",
    "for idx, img in zip(range(shapes[0][0]),train_imgs):\n",
    "    train_imgs_res[idx] = cv2.resize(img, shapes[0][1:-1])\n",
    "\n",
    "for idx, img in zip(range(shapes[1][0]),val_imgs):\n",
    "    val_imgs_res[idx] = cv2.resize(img, shapes[1][1:-1])\n",
    "\n",
    "for idx, img in zip(range(shapes[2][0]),test_imgs):\n",
    "    test_imgs_res[idx] = cv2.resize(img, shapes[2][1:-1])\n",
    "    \n",
    "train_imgs_res = train_imgs_res / 255\n",
    "val_imgs_res = val_imgs_res / 255\n",
    "test_imgs_res = test_imgs_res / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo el modelo con los mismos parámetros que utilicé para el modelo lineal de antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6634 samples, validate on 738 samples\n",
      "Epoch 1/5\n",
      "6634/6634 [==============================] - 55s 8ms/step - loss: 3316.8767 - mean_squared_error: 3316.8765 - val_loss: 3723.5158 - val_mean_squared_error: 3723.5166\n",
      "Epoch 2/5\n",
      "6634/6634 [==============================] - 53s 8ms/step - loss: 3230.2990 - mean_squared_error: 3230.2988 - val_loss: 3596.2180 - val_mean_squared_error: 3596.2183\n",
      "Epoch 3/5\n",
      "6634/6634 [==============================] - 53s 8ms/step - loss: 3182.2551 - mean_squared_error: 3182.2532 - val_loss: 3609.6250 - val_mean_squared_error: 3609.6252\n",
      "Epoch 4/5\n",
      "6634/6634 [==============================] - 53s 8ms/step - loss: 3192.1145 - mean_squared_error: 3192.1125 - val_loss: 3687.6524 - val_mean_squared_error: 3687.6523\n",
      "Epoch 5/5\n",
      "6634/6634 [==============================] - 53s 8ms/step - loss: 3168.5973 - mean_squared_error: 3168.5967 - val_loss: 3587.6928 - val_mean_squared_error: 3587.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b8461e9e08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_model = create_cnn(train_imgs_res.shape[1:], linear=True)\n",
    "imgs_model.compile(loss='mse', optimizer='adam' , metrics=[MeanSquaredError()])\n",
    "imgs_model.fit(train_imgs_res, Y_train, validation_data=(val_imgs_res, Y_val), epochs=5, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en test: 3074.973080124347\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE en test: {np.mean(((imgs_model.predict(test_imgs_res) - Y_test.to_numpy().reshape(-1,1))**2).mean(axis=1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados horribles. Voy a probar con VGG16 cargando los pesos de imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "\n",
    "for shape in (train_imgs.shape, val_imgs.shape, test_imgs.shape):\n",
    "    shapes.append((shape[0],48,48,3)) # Reescalo a 48, 48, 3 para poder usar VGG16\n",
    "    \n",
    "train_imgs_res = np.zeros(shapes[0], dtype=int)\n",
    "val_imgs_res = np.zeros(shapes[1], dtype=int)\n",
    "test_imgs_res = np.zeros(shapes[2], dtype=int)        \n",
    "\n",
    "for idx, img in zip(range(shapes[0][0]),train_imgs):\n",
    "    train_imgs_res[idx] = cv2.resize(img, shapes[0][1:-1])\n",
    "\n",
    "for idx, img in zip(range(shapes[1][0]),val_imgs):\n",
    "    val_imgs_res[idx] = cv2.resize(img, shapes[1][1:-1])\n",
    "\n",
    "for idx, img in zip(range(shapes[2][0]),test_imgs):\n",
    "    test_imgs_res[idx] = cv2.resize(img, shapes[2][1:-1])\n",
    "    \n",
    "train_imgs_res = train_imgs_res / 255\n",
    "val_imgs_res = val_imgs_res / 255\n",
    "test_imgs_res = test_imgs_res / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6634 samples, validate on 738 samples\n",
      "Epoch 1/5\n",
      "6634/6634 [==============================] - 6s 832us/step - loss: 3613.5646 - mean_squared_error: 3613.5645 - val_loss: 3656.6847 - val_mean_squared_error: 3656.6846\n",
      "Epoch 2/5\n",
      "6634/6634 [==============================] - 5s 803us/step - loss: 3030.7333 - mean_squared_error: 3030.7329 - val_loss: 3623.4543 - val_mean_squared_error: 3623.4539\n",
      "Epoch 3/5\n",
      "6634/6634 [==============================] - 5s 805us/step - loss: 3007.2156 - mean_squared_error: 3007.2153 - val_loss: 3613.3821 - val_mean_squared_error: 3613.3818\n",
      "Epoch 4/5\n",
      "6634/6634 [==============================] - 5s 806us/step - loss: 2997.7935 - mean_squared_error: 2997.7930 - val_loss: 3618.2106 - val_mean_squared_error: 3618.2107\n",
      "Epoch 5/5\n",
      "6634/6634 [==============================] - 5s 804us/step - loss: 2983.6958 - mean_squared_error: 2983.6960 - val_loss: 3601.7779 - val_mean_squared_error: 3601.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b87d403488>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=train_imgs_res.shape[1:])\n",
    "vgg16_model = create_cnn(train_imgs_res.shape[1:], base=vgg16_model, linear=True, density=2500, mode='transfer_learning')\n",
    "vgg16_model.compile(loss='mse', optimizer='adam', metrics=[MeanSquaredError()])\n",
    "vgg16_model.fit(train_imgs_res, Y_train, validation_data=(val_imgs_res, Y_val), epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en test: 3084.0637648090647\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE en test: {np.mean(((vgg16_model.predict(test_imgs_res) - Y_test.to_numpy().reshape(-1,1))**2).mean(axis=1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo entrena más rápido pero no me mejora los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí he definido dos funciones que permiten generar modelos lineales y categóricos de una forma sencilla. Ahora voy a trabajar más a fondo con estos dos modelos y a tratar de unificarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
