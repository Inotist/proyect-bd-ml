{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica del módulo NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo todos los twitts y los concateno en un único dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783396985093193728</td>\n",
       "      <td>/missyscheng/status/783396985093193728</td>\n",
       "      <td>False</td>\n",
       "      <td>#DataScience Basics: #DataMining vs. #Statisti...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783381842024103936</td>\n",
       "      <td>/EXASOLAG/status/783381842024103936</td>\n",
       "      <td>False</td>\n",
       "      <td>How to Become a #Data Scientist – Part 1: http...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783433625723252736</td>\n",
       "      <td>/TarasNovak/status/783433625723252736</td>\n",
       "      <td>False</td>\n",
       "      <td>@jesterxl @kdnuggets or just go with @tableau :)</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783428740453982208</td>\n",
       "      <td>/kdnuggets/status/783428740453982208</td>\n",
       "      <td>False</td>\n",
       "      <td>#Boston U. Online MS in Applied #Business #Ana...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1h1 hour ago</td>\n",
       "      <td>787052623291641856</td>\n",
       "      <td>/kdnuggets/status/787052623291641856</td>\n",
       "      <td>False</td>\n",
       "      <td>#ICYMI Still Searching for ROI in #BigData Ana...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          date                  id  \\\n",
       "0           0         Oct 4  783396985093193728   \n",
       "1           1         Oct 4  783381842024103936   \n",
       "2           2         Oct 4  783433625723252736   \n",
       "3           3         Oct 4  783428740453982208   \n",
       "4           4  1h1 hour ago  787052623291641856   \n",
       "\n",
       "                                     link  retweet  \\\n",
       "0  /missyscheng/status/783396985093193728    False   \n",
       "1     /EXASOLAG/status/783381842024103936    False   \n",
       "2   /TarasNovak/status/783433625723252736    False   \n",
       "3    /kdnuggets/status/783428740453982208    False   \n",
       "4    /kdnuggets/status/787052623291641856    False   \n",
       "\n",
       "                                                text   author  \n",
       "0  #DataScience Basics: #DataMining vs. #Statisti...  various  \n",
       "1  How to Become a #Data Scientist – Part 1: http...  various  \n",
       "2   @jesterxl @kdnuggets or just go with @tableau :)  various  \n",
       "3  #Boston U. Online MS in Applied #Business #Ana...  various  \n",
       "4  #ICYMI Still Searching for ROI in #BigData Ana...  various  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = glob.glob('twitter_corpus/*.csv')\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "corpus = pd.concat(li, axis=0, ignore_index=True)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generación de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a convertir todo el texto de los twits en un único documento plano de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corpus = \"\\n\\n\".join(re.sub('[^a-zA-Z0-9!?\\',.:\"]+', '', tweet) for tweet in corpus.sample(25000).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero un diccionario de caracteres y dos conversores que transformen respectivamente cada caracter en su número correspondiente y a la inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(full_corpus)))\n",
    "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero los chunks de texto que se van a utilizar para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 2462049\n"
     ]
    }
   ],
   "source": [
    "# Limit the sentences length to chunks of seq_length characters\n",
    "seq_length = 40\n",
    "\n",
    "# Spaces between sentences\n",
    "step = 1\n",
    "\n",
    "# List to store the sentences\n",
    "sentences = []\n",
    "\n",
    "# List to store the next character to be predicted for each sentence\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(full_corpus)-seq_length, step):\n",
    "    sentences.append(full_corpus[i:i+seq_length])\n",
    "    next_chars.append(full_corpus[i+seq_length])\n",
    "    \n",
    "print('num training examples: {}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero un tensor de frases con cada carácter representado en un vector one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot-encoded vectors\n",
    "X = np.zeros((len(sentences), seq_length, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyo el modelo y lo entreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=50, shuffle=True).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear el modelo, lo mejor es ponerlo a prueba. Ya que no nos interesa tanto el accuracy como el hecho de que sea capaz de generar un texto coherente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = \"I've seen a red unicorn fighting with a giant purple dinosaur. I was so scared that I suddenly woke up.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, seq_length, len(chars)))\n",
    "\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return heapq.nlargest(1, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    for _ in range(200):\n",
    "        x = prepare_input(text[-seq_length:])\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = index_to_char[next_index]\n",
    "\n",
    "        text += next_char\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_completion(prepare_input(example_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y si intento generar texto usando un modelo preentrenado para generar poesía?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
